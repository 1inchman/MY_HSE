{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговое задание по курсу АОТ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Язык программирования python3 (задание E, пункт 2: тематическая классификация на основе векторной модели текста)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Импортируем все необходимые модули для парсинга текстов, извлечения векторов из текста, классификаторы и метрики.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вынесем нерелевантные токены в лист.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ignore_symbs = [',', '-', ':', '!', ';', '(', ')', '–', '\"', '{', '}', '[', ']', '.', '?', '@',\n",
    "                '<', '>', '|', '*', '...']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Воспользуемся размеченной выборкой текстов из модуля scikit-learn.datasets. Модуль содержит размеченные выборки текстов на 20 тематик. Выберем две темы для простоты визуализации: компьютерное железо и религия . Запишем эти сырые тексты в два листа – train и test. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats=['comp.sys.mac.hardware', 'soc.religion.christian']\n",
    "train = fetch_20newsgroups(subset='train', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "test = fetch_20newsgroups(subset='test', categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "train_target = train.target\n",
    "test_target = test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Посмотрим на первые тексты в train и test выборках.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I haven't followed whatever discussion there may have been on these\n",
      "people, but I feel that C. S. Lewis is an excellent apologist and I\n",
      "see no reason for embarrassment.  If you think that errors and flawed\n",
      "arguments are a reason for dismissing a thinker, you must dismiss\n",
      "nearly every thinker from Descartes to Kant; any philosophy course\n",
      "will introduce you to their weaknesses.  \n",
      " \n",
      "  The above also expresses a rather odd sense\n",
      "\n",
      "I said nothing about \"the masses.\"  However comparing \"the masses\" in\n",
      "our day and in Aquinas' day really *is* odd.  Read Ortega y Gasset on\n",
      "this.\n",
      "\n",
      "I'm talking about the familiar experience of arguing all night and\n",
      "winning on logic and evidence, only to discover your opponent to be\n",
      "unaware, even intuitively, of things like entailment (let alone\n",
      "pragmatics).  (I am assuming that both parties are college graduates\n",
      "or better...)  Myself, I don't bother any more.\n",
      "\n",
      "Ken\n"
     ]
    }
   ],
   "source": [
    "print(train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone,\n",
      "\n",
      "I'm trying to find my way to God, but find it difficult as I can't hear\n",
      "God talking to me, letting me know that he exists and is with me and\n",
      "that he knows me, and I feel that I can't possibly get to know him until\n",
      "he does. Maybe he _is_ talking to me but I just don't know or understand\n",
      "how to listen.\n",
      "\n",
      "Some Christians tell me that (in their opinion) the only way to find God\n",
      "is to take a plunge and commit your life to him, and you will discover.\n",
      "This idea of diving into the totally unknown is a little bit\n",
      "frightening, but I have a few questions.\n",
      "\n",
      "1) How do you actually commit yourself? If I just say, \"OK God, her you\n",
      "go, I'm committing my life to you\", I wouldn't really feel that he'd\n",
      "listened - at least, I couldn't be sure that he had. So how does one (or\n",
      "how did you) commit oneself to God?\n",
      "\n",
      "2) In committing myself in this way, what do I have to forfeit of my\n",
      "current life? What can I no longer do? I feel that I'm as 'good' as many\n",
      "Christians, and I try to uphold the idea of 'loving your neighbour' - I\n",
      "don't go round killing people, stealing, etc., and I try not to get\n",
      "jealous of other people in any way - and I would say that I keep to the\n",
      "standards of treating other people as well as many Christians. So what\n",
      "do I have to give up?\n",
      "\n",
      "3) When committed, what do I have to do? What does it involve? What (if\n",
      "any) burdens am I taking on?\n",
      "\n",
      "4) So then, what's the general difference before and after? I assume,\n",
      "that (like on your birthday you don't suddenly feel a year older) it\n",
      "won't suddenly change my life the day I commit myself. So what happens?\n",
      "\n",
      "5) How can I be sure that it is the right thing to do? How can I find\n",
      "out what the 'it' in the last sentence actually _is_?!\n",
      "\n",
      "Thanks very much for all your help in answering these questions. Perhaps\n",
      "e-mail would be a better way to reply, but it's up to you.\n"
     ]
    }
   ],
   "source": [
    "print(test.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Теперь необходимо выбросить из списка токенов знаки препинания, привести слова к нормальной форме и соединить их обратно в текст. Класс word_tokenize из модуля nltk разбивает текст на токены и возвращает лист. Далее лист токенов фильтруется, а класс WordNetLemmatizer приводит слова к нормальной форме. На выходе получаем листы текстов, в которых все слова приведены к нормальной форме. Здесь не используется список стоп-слов, так как в векторизаторах scikit-learn встроен фильтр стоп-слов. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_normal = []\n",
    "test_normal = []\n",
    "for text in train.data:\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = list(filter(lambda x: x not in ignore_symbs, tokens))\n",
    "    wnl = WordNetLemmatizer()\n",
    "    normal_form_list = [wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] \n",
    "                   else wnl.lemmatize(i) for i,j in pos_tag(tokens)]\n",
    "    normal_form = ' '.join(normal_form_list)\n",
    "    normal_form = re.sub(r'\\d+', '', normal_form.replace('*', ''))\n",
    "    train_normal.append(normal_form)\n",
    "    \n",
    "for text in test.data:\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = list(filter(lambda x: x not in ignore_symbs, tokens))\n",
    "    wnl = WordNetLemmatizer()\n",
    "    normal_form_list = [wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] \n",
    "                   else wnl.lemmatize(i) for i,j in pos_tag(tokens)]\n",
    "    normal_form = ' '.join(normal_form_list)\n",
    "    normal_form = re.sub(r'\\d+', '', normal_form.replace('*', ''))\n",
    "    test_normal.append(normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Попробуем две векторные модели текста ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** I. Bag of words ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "train_vectorized = vectorizer.fit_transform(train_normal)\n",
    "test_vectorized = vectorizer.transform(test_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим несколько моделей и посмотрим, как они себя покажут на тестовом множестве. Зададим итератор разбиений для кросс-валидации на 10 фолдов, зададим список моделей и будем искать оптимальные гиперпараметры по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic Regression the score is 0.9507221750212405 with parameters {'random_state': 0, 'C': 10, 'class_weight': None}\n",
      "For Random Forest the score is 0.9252336448598131 with parameters {'n_estimators': 300, 'random_state': 0, 'max_depth': None, 'class_weight': 'balanced'}\n",
      "For Gradient Boosting the score is 0.9362786745964317 with parameters {'n_estimators': 150, 'random_state': 0, 'max_depth': 3}\n",
      "The best estimator is LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "with accuracy = 0.9507221750212405\n"
     ]
    }
   ],
   "source": [
    "cross_validator = StratifiedKFold(y=train_target, n_folds=10, shuffle=True, random_state=0)\n",
    "models = [LogisticRegression(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "models_names = ['Logistic Regression', 'Random Forest', 'Gradient Boosting']\n",
    "best_score_bow = 0\n",
    "param_grids = [{'C': [10**x for x in range(-3, 2)], 'class_weight': [None, 'balanced'], 'random_state': [0]},\n",
    "               {'n_estimators': [100, 200, 300], 'max_depth': [5, 8, None],\n",
    "                'class_weight': [None, 'balanced'], 'random_state': [0]},\n",
    "                {'max_depth': [3], 'n_estimators': [100, 150],\n",
    "                 'random_state': [0]}]\n",
    "for clf, params, name in zip(models, param_grids, models_names):\n",
    "    gs = GridSearchCV(estimator=clf, param_grid=params, scoring='accuracy', cv=cross_validator)\n",
    "    gs.fit(train_vectorized.toarray(), train_target)\n",
    "    print('For {} the score is {} with parameters {}'.format(name, gs.best_score_, gs.best_params_))\n",
    "    if gs.best_score_ > best_score_bow:\n",
    "        best_score_bow = gs.best_score_\n",
    "        best_estimator_bow = gs.best_estimator_\n",
    "\n",
    "print('The best estimator is {}\\nwith accuracy = {}'.format(best_estimator_bow, best_score_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Среднее по валидационным разбиениям показывает хорошие результаты на всех алгоритмах, выберем логистическую регрессию, как алгоритм с самым высоким средним значением accuracy. Проверим теперь этот алгоритм на тестовой выборке. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94       385\n",
      "          1       0.97      0.91      0.94       398\n",
      "\n",
      "avg / total       0.94      0.94      0.94       783\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAF5CAYAAACm4JG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XmYHWWZ///3TYggoBFlUxEQxAAOoulBiaAyoGyugIoN\nqAguKM5oq+PCT2UERUEWxTFfcFAgIq3oD/1GQaIBFGQR7WZTEsUhiCyGgBCFhC25v39UNXQ6vZ3q\n03W6T79f11VXn3pOLfep9JXz6aeeqorMRJIkqU5rtboASZI09RhAJElS7QwgkiSpdgYQSZJUOwOI\nJEmqnQFEkiTVzgAiSZJqZwCRJEm1M4BIkqTaGUAkSVLtJkQAiYhXRsS8iLgzIlZFxBtHsc7uEdET\nEQ9HxJ8i4l111CpJksZuQgQQYH3geuAoYMSH00TEVsBPgUuAnYCvAWdGxGvHr0RJktQsMdEeRhcR\nq4A3Z+a8YZY5Adg3M1/cr60bmJGZ+9VQpiRJGoOJ0gPSqF2ABQPa5gOzW1CLJElq0GQNIJsBSwa0\nLQGeHhHrtKAeSZLUgLVbXUATRflz0HNKEfEsYG/gNuDhmmqSJKkdrAtsBczPzPuascHJGkD+Bmw6\noG0T4B+Z+egQ6+wNfHdcq5Ikqb0dApzXjA1N1gByNbDvgLa9yvah3AZw7rnnsv32249TWeqTCTfd\nBCef3MWRR57KN74BCxe2uqqJ5eCD4c1vbv52Tzihi09+8tTmb3gQz3wmbLhhLbua0Lq6ujj11HqO\nuQoe83otXLiQQw89FMrv0maYEAEkItYHXsCTp1G2joidgL9n5l8j4kvAczKz714fpwMfKq+G+Taw\nJ/AWYLgrYB4G2H777Zk1a9Z4fIy2dNdd0NPT+HoLF8InPwkwgw99qDjeL3gB/OxnTS1v0po2Dbba\nCiJGXLRh3/nODN76Vn/H6zRjxgz/X6mZx7xlmjaEYUIEEOBfgcsoxm8kcHLZfg5wOMWg0+f1LZyZ\nt0XE64BTgP8A7gCOyMyBV8ZoDG68EV79anjggerbeMUroLu7eL3JJrDuus2pTZI0uU2IAJKZv2KY\nK3Iy891DrNMxnnW1i0y48EL4xz8aW++QQ4qfb34znH564/t96lPh0ENhiy0aX1eS1N4mRABRNRdf\nDHffPfJyixbBiSdW28cpp8CHPwxrTdYLtiVJE5IBZJK44gr4wx+enF++HD72sdGvv/ba8PvfN9Yb\nETH2UyadnZ1j24Aa5jGvn8e8fh7zyW/C3Yp9vETELKCnp6dnUgxcWrwYfvKT4vQJwEc+UvycNq34\nuXJlERCuuAJ22WXk7UXYiyFJqqa3t5eOjg6AjszsbcY27QGZgC6+GN7+9qKXY/r0om3aNDjnnCfH\nZUiSNJn5N/EEkgknnAD77Qe77QZLl8JDDxXT448bPiRJ7cMAMkE89BB0dsKnPgVHHw3z5sGMGa2u\nSpKk8eEpmAngttuKS13//Gf4wQ/gLW9pdUWSJI0vA0iLXXopvO1tRW/H1VfDjju2uiJJksafp2Ba\nJBO++lXYay+YNQt++1vDhyRp6jCAtMCKFXDYYdDVVUwXXVQ81EuSpKnCUzA1++tf4YADipuCnXuu\nV7ZIkqYmA0iNfv1rOPBAWGcduPLK4tSLJElTkadganL66fBv/wbbbQe/+53hQ5I0tRlAxtkjj8D7\n3w8f+AAceSQsWFA8ll6SpKnMUzDj6O67i3t6/O538K1vweGHt7oiSZImBgPIOLn2Wth//+Jy21/9\nanQPjJMkaarwFMw4uPZaeOUrYcstoafH8CFJ0kAGkCY7+2x4+cvh0Ufhssvg2c9udUWSJE08BpAm\n+9WvitAxZ05xua0kSVqTAWQcbL11cdWLJEkanINQx+i224r7eyxbBk95SvFz551bXZUkSRObAaSi\n44+Hr3wFHnigmD/iCHj+84vXr3pV6+qSJGkyMIBUdMMNsPHGcPTRsOGGRQCJaHVVkiRNDgaQUbrp\nJpg9Gx5+uJhfuRL23Rf+8z9bW5ckSZORAWSUbr0VHnoIvvSloscDYNddW1uTJEmTlQFkFL797eIU\nCxQ/N964tfVIkjTZeRnuKNxxBzzjGTB/vuFDkqRmMICM0nrrwV57tboKSZLaw4QJIBFxVEQsjogV\nEXFNRAx5N42IWDsiPhcRfy6Xvy4i9h6Puh55BO67bzy2LEnS1DUhxoBExEHAycD7gGuBLmB+RLww\nM+8dZJUvAgcD7wH+COwD/CgiZmfmDWOpJRP+/OcieAAcfjj89rfwgheMZauSJKm/idID0gWckZlz\nM3MRcCSwHDh8iOUPBb6YmfMz87bMPB24CPjYWIp49FE46SR44Qthxx2L6be/hW22gQULxrJlSZLU\nX8t7QCJiOtABHN/XlpkZEQuA2UOstg7wyIC2FcBuVev4+9/hne+ECy8s5i+5pBj3AbD99jBjRtUt\nS5KkgVoeQICNgGnAkgHtS4CZQ6wzH/hoRFwB/C/wGuAAxtCjc9hhRfh4+tOLm45tsUXVLUmSpJFM\nhAAylAByiPc+DHwTWASsoggh3wbePdJGu7q6mDGgO+NVr+rk9ts72W8/+O53i0tuJUmairq7u+nu\n7l6tbdmyZU3fz0QIIPcCK4FNB7Rvwpq9IgCUA1MPiIinAM/KzLsj4svA4pF2duqppzJr1qzVd7QJ\nLF0Kr3yl4UOSNLV1dnbS2dm5Wltvby8dHR1N3U/LB6Fm5mNAD7BnX1tERDl/1QjrPlqGj+nAgcCP\nq9SwYgV89rPw1a9WWVuSJDVqIvSAAJwCnBMRPTx5Ge56wNkAETEXuCMzjy7nXwY8F7ge2Bw4huKU\nzVeqFrDhhjBt2hg+gSRJGrUJEUAy8/yI2Ag4luJUzPXA3pm5tFxkc+DxfqusC3wBeD7wIHAhcGhm\n/qOx/cIFF8Bjj431E0iSpEZMiAACkJlzgDlDvLfHgPnLgReNdZ+33gpveQtEwJZbjnVrkiRptCZM\nAGmFvp6PX/4SXvWqlpYiSdKU0vJBqBPBWh4FSZJq5VevJEmqnQFEkiTVzgAiSZJqNyUHoV53HZx9\ndvEAOkmSVL8pGUDOOgu++U3Ydlt4+cthm21aXZEkSVPLlAsg8+fDggUwcybccEOrq5EkaWqacmNA\nurvhvvuKG5BJkqTWmHIBBOANbygePidJklpjSgYQSZLUWgYQSZJUOwOIJEmqnQFEkiTVbsoFkFtu\naXUFkiRpygWQ7beH97yn1VVIkjS1TbkAsu++sMsura5CkqSpbcoFEEmS1HoGEEmSVDsDiCRJqp0B\nRJIk1c4AIkmSamcAkSRJtTOASJKk2hlAJElS7QwgkiSpdgYQSZJUuwkTQCLiqIhYHBErIuKaiNh5\nhOU/EhGLImJ5RNweEadExDp11StJkqqbEAEkIg4CTgaOAV4K3ADMj4iNhlj+YOBL5fLbAYcDBwFf\nrKVgSZI0JhMigABdwBmZOTczFwFHAsspgsVgZgO/zszvZ+btmbkA6AZeVk+5kiRpLFoeQCJiOtAB\nXNLXlpkJLKAIGoO5CujoO00TEVsD+wEXjm+1kiSpGdZudQHARsA0YMmA9iXAzMFWyMzu8vTMryMi\nyvVPz8wTxrVSSZLUFC3vARlGADnoGxG7A0dTnKp5KXAA8PqI+Ext1UmSpMomQg/IvcBKYNMB7Zuw\nZq9In2OBuZl5Vjn/h4jYADgD+MJwO/vBD7q46aYZq7V1dnbS2dnZaN2SJLWd7u5uuru7V2tbtmxZ\n0/fT8gCSmY9FRA+wJzAPoDytsidw2hCrrQesGtC2qlw1yjEkg3rrW0/li1+cNfbCJUlqQ4P9Ud7b\n20tHR0dT99PyAFI6BTinDCLXUlwVsx5wNkBEzAXuyMyjy+V/AnRFxPXAb4BtKXpF/u9w4UOSJE0M\nEyKAZOb55aDSYylOxVwP7J2ZS8tFNgce77fKcRQ9HscBzwWWUvSeOAZEkqRJYEIEEIDMnAPMGeK9\nPQbM94WP42ooTZIkNdlEvgpGkiS1KQOIJEmqnQFEkiTVbsoFkG22aXUFkiRpygWQl7yk1RVIkqQp\nF0AkSVLrGUAkSVLtDCCSJKl2BhBJklQ7A4gkSaqdAUSSJNXOACJJkmpnAJEkSbWrFEAiYq2I2C0i\n3hURG5RtG0XEU5tbniRJakdrN7pCRGwOXAhsB0wDrgAeBP4LCOCoJtYnSZLaUJUekK8BC4FnACv6\ntV8AvLYZRUmSpPbWcA8I8CrgVZm5IiL6t98KbN6UqiRJUlur0gMyfYj251CcipEkSRpWlQCygNXH\neWQ5+PQY4OKmVCVJktpalVMwHwMWREQvsA5wFjATeAg4rHmlSZKkdtVwAMnMv0TEi4B3ADsBGwA/\nBM7JzH82uT5JktSGqlyG+zKgJzO/NaB9WkS8LDOvbVp1kiSpLVUZA3I18KxB2p9RvidJkjSsKgEk\ngBykfUNg+djKkSRJU8GoT8FExHnlywTOiIiH+709DXgJcE0Ta5MkSW2qkR6QGGZ6GPgexcBUSZKk\nYY26ByQzOwEi4jbgC5n50HgVJUmS2luVy3A/PR6FSJKkqaPKIFQi4vURMTcifhkRV/WfqhYSEUdF\nxOKIWBER10TEzsMse1lErBpk+knV/UuSpPo0HEAi4gPA94FHgNnAH4GVwA7AlVWKiIiDgJMpbuf+\nUuAGYH5EbDTEKvsDm/Wb/qWs4fwq+5ckSfWq0gPyH8CRmfle4FHguMx8JXA6Qz+obiRdwBmZOTcz\nFwFHUlzSe/hgC2fmA5l5T98E7EVxK/gfVty/JEmqUZUAsiVwefn6YeBp5etvAYc0urGImA50AJf0\ntWVmUjz0bvYoN3M40J2ZKxrdvyRJql+VAHIPxU3HAG4H/rV8/TyqPdxuI4r7iCwZ0L6E4vTKsMpb\nw78IOLPCviVJUgtUCSCXAa8vX38H+Fo5+PN8oJmDQIe64+pARwC/z8yeJu5bkiSNoyo9Fu/vWy8z\nvxoRDwCvAE4Avl5he/dSDCDddED7JqzZK7KaiHgqcBDwmdHurKurixkzZqzW1tnZSWdn52g3IUlS\n2+ru7qa7u3u1tmXLljV9P1EMtxjlwhFrAx8FvpuZdzatiIhrgN9k5ofL+aA4vXNaZn5lmPUOA+YA\nz83M+0fYxyygp6enh1mzZjWrdEmS2l5vby8dHR0AHZnZ24xtNnQKJjMfBz5HtZ6T4ZwCvC8i3hkR\n21FcUbMecDZAec+R4wdZ7wjgxyOFD0mSNLFUCRK/AnYD/tKsIjLz/PKeH8dSnIq5Htg7M5eWi2wO\nPN5/nYjYluLUz2ubVYckSapHlQByAXBiRGwP9FDcf+MJmfnzKoVk5hyK0ymDvbfHIG23UFw9I0mS\nJpkqAeR/yp9HD/JeYiiQJEkjqBJAntr0KiRJ0pRS5Wm4j4xHIZIkaeqo9DRcSZKksTCASJKk2hlA\nJElS7QwgkiSpdpUCSERsERGfiYizImLjsm3PiJjZ3PIkSVI7ajiARMQrgJuBvYGDgaeVb+0CHNe8\n0iRJUruq0gNyIvCFzHwl8Gi/9gXA7KZUJUmS2lqVALIT8P1B2pcAG4+tHEmSNBVUCSD/ADYZpP3F\nwF1jK0eSJE0FVQLID4AvR8QzKZ79khHRAZwEnNfM4iRJUnuqEkA+BdwB/A1YH/gDcC1wA/D55pUm\nSZLaVZVnwTwMvCMijgV2BDYAejPz980uTpIktaeGA0hEdGRmT2beAtwyDjVJkqQ2V+UUzG8iYlF5\nI7Ktm16RJElqe1UCyBbAmcD+wC0RcXVEHNV3R1RJkqSRNBxAMvOuzDwpMzuAF1HcgKwLuDMiLmp2\ngZIkqf2M6WF0mbkI+BxwJMXVMHs3oyhJktTeKgeQiOiIiFMoLsmdB/wv8JZmFSZJktpXlatgPgcc\nAmwNXA58FvhhZv6jybVJkqQ21XAAAd4MfBPozkxvvS5JkhpW5UZks8ajEEmSNHWMKoBExF7ApZn5\nePl6SJn586ZUJkmS2tZoe0AuBjYD7ilfDyWBaWMtSpIktbfRBpCnZuYjfa/HqxhJkjQ1jOoy3H7h\nA+BNRVM+0n8CVpXvSZIkDavKfUC6gWcM0v708r1Kytu5L46IFRFxTUTsPMLyMyLiGxFxV7nOoojY\np+r+JUlSfapchhsUYz0GejZQ6V4gEXEQcDLwPuBailu7z4+IF2bmvYMsP53iFvB/Aw4A7gK2BB6o\nsn9JklSvUQeQiLiaIngkcFFEPNbv7WnAtsBlFevoAs7IzLnlvo4EXgccDpw4yPJHUPTC7JKZK8u2\n2yvuW5Ik1ayRHpBflj93Aa4GHur33qPA6cD3Gy2g7M3oAI7va8vMjIgFwOwhVntDWcOciHgTsBQ4\nDzghM1c1WoMkSarXqANIZn4aICJuA87JzIebVMNGFD0oSwa0LwFmDrHO1sAewLnAvhS9L3PK7Xyh\nSXVJkqRxUuVOqGeMRyGDGGqsCRSDZ5cA78vMBK6LiOcCH2eEANLV1cWMGTNWa+vs7KSzs3PsFUuS\nNMl1d3fT3b36NSXLli1r+n6i+P4eYaGIu4AdM/O+iLiboYMBmfmchgooTsEsBw7MzHn92s8GZmTm\n/oOs80vg0czcq1/bPsCFwDqZ+fgg68wCenp6epg1y7vJS5I0Wr29vXR0dAB0ZGZvM7Y52h6QzwMP\n9ns9cmoZpcx8LCJ6gD2BeQAREeX8aUOsdiUwsMtiJnD3YOFDkiRNLKMKIP1Pu2Tm6eNQxynAOWUQ\n6bsMdz3gbICImAvckZlHl8v/H+BDEfE14L+BFwKfBr46DrVJkqQma3gMSETsCDyemQvL+X2BdwE3\nA8dX6YHIzPMjYiPgWGBT4Hpg78xcWi6yOfB4v+XvKB+KdypwA3Bn+XqwS3YlSdIEU+VGZGcCJwEL\nI2JL4ALgZ8C7Ke6G+vEqhWTmHIorWQZ7b49B2n4DvKLKviRJUmtVuRX7dsB15eu3AVdm5gHAO8t5\nSZKkYVUJIP3XeQ3FlScAfwE2HnNFkiSp7VUJIL3AJyLircC/AReV7VsC9zSrMEmS1L6qBJAuiuAx\nFzg5M/9Yth9IcXt0SZKkYVW5E2ovxa3PB/oc8Ngg7ZIkSaupchUMABHxImB7ipuSLczMm5tWlSRJ\namtV7gPyLOA7wD7ACopntqwTERcD78jMvze3REmS1G6qjAE5DXgOxf3g18/M9YCdgecCX2tmcZIk\nqT1VOQWzH7BPZvbdC4TM7I2ID/DkFTGSJElDqtIDMp3i1MtAyxnDmBJJkjR1VAkgvwROiYgnbjoW\nEZtQ3J79l80pS5IktbMqPRb/DvwUuD0ibqW4CmYb4H+B1zexNkmS1Kaq3AdkcflE3NdRPBcmKJ6E\ne1FmrmpyfZIkqQ1VGrNRBo2flJMkSVJDqowBISJ2i4gfRsQfIuL35evdml2cJElqTw0HkIh4D8Vg\n02nAORTPhFkLuCwi3tvU6iRJUluqcgrmc8B/Zuap/Rsj4iPle//TjMIkSVL7qnIK5pkMPvbjp+V7\nkiRJw6oSQC5i8MttXw9cPLZyJEnSVFDlFEwPcEw56PSasm0XYA/gyxHxvr4FM/ObYy9RkiS1myoB\n5CPAw8Cu5dTnEaCr33wCBhBJkrSGKjcie/Z4FCJJkqaOSvcBkSRJGgsDiCRJqp0BRJIk1c4AIkmS\namcAkSRJtav6MLqXRcSZEXFZRDynbHt7ROzS3PIkSVI7qvIwujcCvwLWAWYD65ZvbQJ8pmohEXFU\nRCyOiBURcU1E7DzMsu+KiFURsbL8uSoillfdtyRJqleVHpBjgA9l5juAx/q1/xroqFJERBwEnFxu\n+6XADcD8iNhomNWWAZv1m7assm9JklS/KgFkO+CSQdofADasWEcXcEZmzs3MRcCRwHLg8GHWycxc\nmpn3lNPSivuWJEk1qxJA7gGeP0j7bGBxoxuLiOkUPSdPhJrMTGBBuc2hbBARt0XE7RHx44jYodF9\nS5Kk1qgSQM4CvhoRO1E87+VZEXEgcBLVnv2yETANWDKgfQnFqZXB/JGid+SNwCEUn+OqiHhuhf1L\nkqSaVXkY3ReA6cDVFANQrwEeB07LzFObWFtQBJw1ZOY1PPkkXiLiamAh8D6KcSRD6urqYsaMGau1\ndXZ20tnZOdZ6JUma9Lq7u+nu7l6tbdmyZU3fTxRnOyqsGLE+MBPYALgpM++vuJ3pFOM9DszMef3a\nzwZmZOb+o9zO+cBjmXnIEO/PAnp6enqYNWtWlVIlSZqSent76ejoAOjIzN5mbLPyjcgy86HM7M3M\ny6uGj3I7jwE9wJ59bRER5fxVo9lGRKwF/Atwd9U6JElSfRo+BRMRFw33fmbuV6GOU4BzIqIHuJbi\nqpj1gLPLfc4F7sjMo8v5z1Kcgvkz8AzgExSX4Z5ZYd+SJKlmVcaA/GXA/HTgJcALgO41Fx9ZZp5f\n3vPjWGBT4Hpg736X1m5OMc6kz4YUA143A+6n6EGZXV7CK0mSJriGA0hmfmCw9og4nmLgaCWZOQeY\nM8R7ewyY/yjw0ar7kiRJrdXMh9GdBby3iduTJEltqpkBZBar35pdkiRpUFUGoZ43sAl4NrArcGIz\nipIkSe2tyiDUgeM8VlEMGj2l/308JEmShtJQAImIacCpwB8zs/m3RZMkSVNCQ2NAMnMlcAXwrPEp\nR5IkTQVVBqHeDDyv2YVIkqSpo0oA+QRwUkS8JiI2jIin9J+aXaAkSWo/VQahzh/wc6BpFWuRJElT\nRJUAsm/Tq5AkSVPKqANIRHwOOCkzh+r5kCRJGpVGxoAcA2wwXoVIkqSpo5EAUvlBc5IkSf01ehVM\njksVkiRpSml0EOqfImLYEJKZzxxDPZIkaQpoNIAcA3gLdkmSNCaNBpDvZeY941KJJEmaMhoZA+L4\nD0mS1BReBSNJkmo36lMwmVnluTGSJElrMFRIkqTaGUAkSVLtDCCSJKl2BhBJklQ7A4gkSaqdAUSS\nJNXOACJJkmpnAJEkSbWbMAEkIo6KiMURsSIiromInUe53tsjYlVEXDDeNUqSpOaYEAEkIg4CTqZ4\n2u5LgRuA+RGx0QjrbQl8Bbh83IuUJElNMyECCNAFnJGZczNzEXAksBw4fKgVImIt4Fzgc8DiWqqU\nJElN0fIAEhHTgQ7gkr62zExgATB7mFWPAe7JzLPGt0JJktRso34Y3TjaCJgGLBnQvgSYOdgKEbEr\n8G5gp/EtTZIkjYeJEECGEkCu0RixAfAd4L2ZeX+jG+3q6mLGjBmrtXV2dtLZ2Vm1TkmS2kZ3dzfd\n3d2rtS1btqzp+4nibEfrlKdglgMHZua8fu1nAzMyc/8By+8E9AIrKUIKPHkqaSUwMzPXGBMSEbOA\nnp6eHmbNmtX0zyFJUrvq7e2lo6MDoCMze5uxzZaPAcnMx4AeYM++toiIcv6qQVZZCOwIvITiFMxO\nwDzg0vL1X8e5ZEmSNEYT5RTMKcA5EdEDXEtxVcx6wNkAETEXuCMzj87MR4Gb+68cEQ9QjF1dWGvV\nkiSpkgkRQDLz/PKeH8cCmwLXA3tn5tJykc2Bx1tVnyRJaq4JEUAAMnMOMGeI9/YYYd13j0tRkiRp\nXLR8DIgkSZp6DCCSJKl2BhBJklQ7A4gkSaqdAUSSJNXOACJJkmpnAJEkSbUzgEiSpNoZQCRJUu0M\nIJIkqXYGEEmSVDsDiCRJqp0BRJIk1c4AIkmSamcAkSRJtTOASJKk2hlAJElS7QwgkiSpdgYQSZJU\nOwOIJEmqnQFEkiTVzgAiSZJqZwCRJEm1M4BIkqTaGUAkSVLtDCCSJKl2BhBJklS7CRNAIuKoiFgc\nESsi4pqI2HmYZfePiN9GxP0R8WBEXBcRh9ZZryRJqm5CBJCIOAg4GTgGeClwAzA/IjYaYpX7gC8A\nuwA7AmcBZ0XEa2soV5IkjdGECCBAF3BGZs7NzEXAkcBy4PDBFs7MyzPz/2bmHzNzcWaeBtwI7FZf\nyZIkqaqWB5CImA50AJf0tWVmAguA2aPcxp7AC4FfjUeNkiSpudZudQHARsA0YMmA9iXAzKFWioin\nA3cC6wCPAx/MzEvHq0hJktQ8EyGADCWAHOb9fwI7ARsAewKnRsStmXl5HcVJkqTqJkIAuRdYCWw6\noH0T1uwVeUJ5mubWcvbGiNgB+DQwbADp6upixowZq7V1dnbS2dnZYNmSJLWf7u5uuru7V2tbtmxZ\n0/cTxfd4a0XENcBvMvPD5XwAtwOnZeZXRrmNbwHPz8w9hnh/FtDT09PDrFmzmlS5JEntr7e3l46O\nDoCOzOxtxjYnQg8IwCnAORHRA1xLcVXMesDZABExF7gjM48u5z8F/A74X4oxIK8DDqW4ekaSJE1w\nEyKAZOb55T0/jqU4FXM9sHdmLi0X2ZxioGmf9YFvlO0rgEXAIZn5w/qqliRJVU2IAAKQmXOAOUO8\nt8eA+c8Cn62jLkmS1Hwtvw+IJEmaegwgkiSpdgYQSZJUOwOIJEmqnQFEkiTVzgAiSZJqZwCRJEm1\nM4BIkqTaGUAkSVLtDCCSJKl2BhBJklQ7A4gkSaqdAUSSJNXOACJJkmpnAJEkSbUzgEiSpNoZQCRJ\nUu0MIJIkqXYGEEmSVDsDiCRJqp0BRJIk1c4AIkmSamcAkSRJtTOASJKk2hlAJElS7QwgkiSpdgYQ\nSZJUOwOIJEmq3YQJIBFxVEQsjogVEXFNROw8zLLviYjLI+Lv5fSL4ZZX63R3d7e6hCnHY14/j3n9\nPOaT34QIIBFxEHAycAzwUuAGYH5EbDTEKq8GzgN2B3YB/gr8PCKePf7VqhH+J1E/j3n9POb185hP\nfhMigABdwBmZOTczFwFHAsuBwwdbODPfkZmnZ+aNmfkn4D0Un2XP2iqWJEmVtTyARMR0oAO4pK8t\nMxNYAMwe5WbWB6YDf296gZIkqelaHkCAjYBpwJIB7UuAzUa5jROAOylCiyRJmuDWbnUBwwggR1wo\n4lPA24BXZ+ajwyy6LsDChQubU51GZdmyZfT29ra6jCnFY14/j3n9POb16vfduW6zthnF2Y7WKU/B\nLAcOzMx5/drPBmZk5v7DrPtx4Ghgz8y8boT9HAx8tylFS5I0NR2Smec1Y0Mt7wHJzMcioodiAOk8\ngIiIcv7QdSFEAAALtElEQVS0odaLiP+kCB97jRQ+SvOBQ4DbgIfHWLYkSVPJusBWFN+lTdHyHhCA\niHgbcA7wfuBaiqti3gJsl5lLI2IucEdmHl0u/wngWKATuKrfph7MzIdqLV6SJDWs5T0gAJl5fnnP\nj2OBTYHrgb0zc2m5yObA4/1W+QDFVS8/HLCpz5fbkCRJE9iE6AGRJElTy0S4DFeSJE0xBhBJklS7\ntgkgjTzMrlz+rRGxsFz+hojYt65a24UPEKxfo7/n/dZ7e0SsiogLxrvGdlPh/5YZEfGNiLirXGdR\nROxTV73toMIx/0h5nJdHxO0RcUpErFNXvZNdRLwyIuZFxJ3l/xNvHMU6u0dET0Q8HBF/ioh3Nbrf\ntgggjT7MLiJmUzzM7n+AlwA/Bn4cETvUU/Hk5wME61fhmPettyXwFeDycS+yzVT4v2U6xR2ZtwAO\nAGYC76W4U7NGocIxPxj4Urn8dhTPEDsI+GItBbeH9Sku/jiK0d0AdCvgpxSPUNkJ+BpwZkS8tqG9\nZuakn4BrgK/1mw/gDuATQyz/PWDegLargTmt/iyTZWr0mA+y/lrAMuDQVn+WyTJVOeblcb4CeDdw\nFnBBqz/HZJoq/N9yJHALMK3VtU/WqcIx/zrwiwFtJwGXt/qzTMYJWAW8cYRlTgBuHNDWDVzUyL4m\nfQ9IxYfZzWbN58bMH2Z59eMDBOs3hmN+DHBPZp41vhW2n4rH/A2Uf8xExN8i4qaI+HRETPr/a+tQ\n8ZhfBXT0naaJiK2B/YALx7faKW0XmvAdOiHuAzJGwz3MbuYQ62w2xPKjffjdVFflmA/kAwQb0/Ax\nj4hdKXo+dhrf0tpWld/zrYE9gHOBfYFtgTnldr4wPmW2lYaPeWZ2l6dnfl3eRXsacHpmnjCulU5t\nQ32HPj0i1snMR0azkXYIIEMZ1cPsxrC81tTsBwhqZIMe84jYAPgO8N7MvL/2qtrbcL/na1H8R/y+\n8i/36yLiucDHMYCMxZDHPCJ2p3gsx5EUd9J+AXBaRNydmR7z+kT5c9Tfo+0QQO4FVlLcQbW/TVgz\nofX5W4PLa3VVjjnwxAMEP0HxAME/jE95banRY74NsCXwk/KvQigHnUfEo8DMzFw8TrW2iyq/53cD\nj5bho89CYLOIWDszHx9iPRWqHPNjgbn9TjP+oQzgZ2DoGy9DfYf+o5E/Kif9ecnMfAzoe5gdsNrD\n7K4aYrWr+y9fem3ZrhFUPOZ9DxD8/yhusz+aBwiqVOGYLwR2pLjKa6dymgdcWr7+6ziXPOlV/D2/\nkuIv8P5mAncbPkZW8ZivRzFwsr9V5aoxyPIau8G+Q/ei0e/QVo+4bdKo3bcBK4B3UlyGdQZwH7Bx\n+f5c4Ph+y88GHgU+SvGfw39RPCF3h1Z/lskyVTjmnyiP8f4UyblvWr/Vn2WyTI0e80HW9yqYcT7m\nFM+tWkZxWeK2wOso/lr8VKs/y2SZKhzzY4AHKC693Yrij8lbgPNa/Vkmy0RxUcBOFH+wrAI+Us4/\nr3z/S8A5/ZbfCniQYizfTOCD5XfqaxrZbzucgiEbfJhdZl4dEZ0U14l/keKX9U2ZeXO9lU9ejR5z\nfIDgmFU45hqjCv+33BERewGnUty/4s7y9Ym1Fj6JVfg9P47iS/M44LnAUorevs/UVvTk96/AZRTj\nN5LiPixQPKX+cIpBp8/rWzgzb4uI1wGnAP9BcZn0EZnZ0EUFPoxOkiTVbtKPAZEkSZOPAUSSJNXO\nACJJkmpnAJEkSbUzgEiSpNoZQCRJUu0MIJIkqXYGEEmSVDsDiCRJqp0BRGojEbFNRKyKiB1aXUtV\nEXFFRAx76/KIOCIi7qmrJknNZwCRJpCIOKsMECvLn32vt25gM5P9+QpvoHhGEAAR8deI+OCAZc4F\nJmTIiohp5b/bfq2uRZrI2uJhdFKb+RlwGND/UeJLB190UJP6EeSZ+cAolnkEeKSGcp4QEWsVux7x\nAVqT+vhLdbEHRJp4HsnMpZl5T78pASJiv4j4dUTcHxH3RsS8iHj+UBuKiA0j4ryIuCcilkfEoog4\ntN/7W0TED/pt70cR8bxhtrdn+df9PhFxY0SsiIgrI2L7Acu9NSL+EBGPRMTiiPjIgPf/PSJuiYiH\nI+JvEdHd770nTsFExBUUTzj9ernfR8v290TE0vL1DuV72wzYxyciYmG/+R0j4uKIeDAi7o6IsyPi\nmcN81iMiYmlEvCkibgYeBp4dES+LiF+Ux+uBiLg0Inbqt+piil6on5Z1/anfNg+IiN7yuN0SEZ8p\ng4005fiLL00uTwW+AswC9qT4a/v/H2b5LwEvAPYGtgM+CNwHEBHTgZ8D9wK7ArsBK4CfjeJL8USK\nx3DvDDwAzOtbJyJeBnQD3wFeRHE65fiIOLh8fxeKx31/Gti2rO3XQ+znjcDd5bKbUYQRePKx4WTm\nzRSPbD94wLqdFKdqiIgNgUuBa4CXAPuW2zpvhM/5NOBjFD1S/0Jx7J4GfBvYpZwWAxdFxFPLdXam\n+Hc5pKx5l7KG3YEzy8++HfAB4AjgkyPUILWnzHRycpogE3AW8Bjwz37T94dZfjNgFfDCcn6bcn6H\ncv5C4Iwh1n0XcOOAtnUoQsjuQ6yzZ7n9N/drexawvK8N+B7w0wHrnQxcV75+K0XoWW+IfVwBnNhv\n/q/ABwcscwRwT7/5jwML+83vAKwEnl/OHwP8ZMA2tio/y1ZD1HFEuY3tRvg3mwY8COzVb34VsN+A\n5S4DPjbIv8FfWv175+TUiskeEGniuRR4MbBTOf1H3xsRsW1EfC8ibo2IfwC3UPQEbDHEtuYA74iI\nnoj4ckS8vN97OwHbR8Q/+yaKYDCdIsgMJSl6EoqZzPuAPwN9p2G2B64csM6VwMzy9cXA34DFEXFO\nRHRGxLrD7G80uoFtI2JWOX8I8JvMXFzO7wTsNeCz3lR+luE+64rMXNS/ISI2i4gzI+JPEfEARQ/Q\nugz9b9DnxcCxA2r4P8Bzyt4oaUpxEKo08TzU74tzoAuBPwGHU5yaeApwQ/lzDZl5YURsAbwOeA1w\nWUR8NTOPBjagCBLvZM2Bk40Men1id+XPYM0rcZ7Yfmb+sxwzsTuwF3AccExE/GtmPlhhv2TmnRFx\nOcVpmF7g7RS9Ln02AH5EcSpn4Ge9a5hNLx+k7VxgfeDfgdspBsP+jiH+DQbU8Elg3iD1PzbCulLb\nMYBIk0REbEIxnuMdmfmbsm131vyyX20+M+8FzgHOiYirgWOBoym+qN9EcSrjoUZKoRjX8OOyhmeV\ndfUN+LyZYjxJf7sCT/QkZOZK4BLgkog4jqIXYXfgp4Ps71GK0xoj+S7w+Yj4EfA84Px+7/VShLDb\nMnOslym/Anh3Zs4HKAcBP6PvzcxcGRErB6n5OmBmZt46xv1LbcFTMNLkcR9wP/D+iNg6IvakGJA6\n0BN/4UfEcRHxhihuUPYvwH4UAQGKQaLLgB9FxK4RsVVE/FtEfD0iNh2hlv+KiN0jYkeKcHMXT4aH\nk4G9I+LT5SmjdwPv76s1It4YER+KiBeXvTOHUYyZ+OMQ+7oNeHVEPGe4q1aAH1KMR/lv4Bdl8Orz\ndWBT4LyI6CiP3z4RcdYIn3MwtwDvjIiZETGb4vOvGLDM7cBrImLTiOgLJ58HDi+vfNm+nN4eEZ9H\nmoIMINIkUfYaHAS8HPg9xRf6xwdbtN/rx4AvU5ymuYziUtJDy+09BLyKIjxcQBFMzuDJQZVDlkJx\nKuO/gWuBDYE3lvWRmb+lOAVyCMU4i88Cn87Mvktt7wfeQjHW5WaK00kHZeYtg9RPuf62wK0UY0cG\nLypzGXARxViL7w54706KXpinAL8AbqQISvcN8zmHchiwMUWPxreBUwbZThewD0UQubas4WcUV/Xs\nS3HK5irgwxRX0UhTToy9N1LSVFH2uvwceFpmDjY+QpJGxR4QSZJUOwOIJEmqnadgJElS7ewBkSRJ\ntTOASJKk2hlAJElS7QwgkiSpdgYQSZJUOwOIJEmqnQFEkiTVzgAiSZJq9/8AgnV8cL+/FNMAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ec315f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve score = 0.9900345885270507\n",
      "Accuracy = 0.9399744572158365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "pred = best_estimator_bow.predict_proba(test_vectorized.toarray())[:,1]\n",
    "print(classification_report(test_target, best_estimator_bow.predict(test_vectorized.toarray())))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_target, pred)\n",
    "acc = metrics.accuracy_score(y_pred=best_estimator_bow.predict(test_vectorized.toarray()), y_true=test_target)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n",
    "print('Area under ROC curve score = {}'.format(roc_auc_score(test_target, pred)))\n",
    "print('Accuracy = {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** II. a) TF-IDF ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "train_tfidf = vectorizer_tfidf.fit_transform(train_normal)\n",
    "test_tfidf = vectorizer_tfidf.transform(test_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим шаг с выбором моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic Regression the score is 0.9668649107901445 with parameters {'random_state': 1, 'C': 10, 'class_weight': None}\n",
      "For Random Forest the score is 0.9668649107901445 with parameters {'n_estimators': 100, 'random_state': 0, 'max_depth': None, 'class_weight': 'balanced'}\n",
      "For Gradient Boosting the score is 0.9668649107901445 with parameters {'n_estimators': 150, 'random_state': 0, 'max_depth': 3}\n",
      "The best estimator is LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "with accuracy = 0.9668649107901445\n"
     ]
    }
   ],
   "source": [
    "cross_validator = StratifiedKFold(y=train_target, n_folds=10, shuffle=True, random_state=0)\n",
    "models = [LogisticRegression(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "models_names = ['Logistic Regression', 'Random Forest', 'Gradient Boosting']\n",
    "best_score_tfidf = 0\n",
    "param_grids = [{'C': [10**x for x in range(-3, 2)], 'class_weight': [None, 'balanced'], 'random_state': [1]},\n",
    "               {'n_estimators': [100, 200, 300], 'max_depth': [5, 8, None],\n",
    "                'class_weight': [None, 'balanced'], 'random_state': [0]},\n",
    "                {'max_depth': [3], 'n_estimators': [100, 150],\n",
    "                 'random_state': [0]}]\n",
    "for clf, params, name in zip(models, param_grids, models_names):\n",
    "    gs = GridSearchCV(estimator=clf, param_grid=params, scoring='accuracy', cv=cross_validator)\n",
    "    gs.fit(train_tfidf.toarray(), train_target)\n",
    "    if gs.best_score_ > best_score_tfidf:\n",
    "        best_score_tfidf = gs.best_score_\n",
    "        best_estimator_tfidf = gs.best_estimator_\n",
    "    print('For {} the score is {} with parameters {}'.format(name, best_score_tfidf, gs.best_params_))\n",
    "\n",
    "\n",
    "print('The best estimator is {}\\nwith accuracy = {}'.format(best_estimator_tfidf, best_score_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       385\n",
      "          1       0.98      0.94      0.96       398\n",
      "\n",
      "avg / total       0.96      0.96      0.96       783\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAF5CAYAAACm4JG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xl4bXV97/H3hyOKgj1aKOAEiFKGitSTwoWihYqCoGId\n6VHUKuJQqvVU5QrXeipYRwbRlgu3tghSotarLSoVxaFOIL0niK2A0gJFBgEHDmUezvf+sVYgJyQ5\nyc7OSrLzfj3PerL3b03fvZIn+WSt32+tVBWSJEld2mi+C5AkSUuPAUSSJHXOACJJkjpnAJEkSZ0z\ngEiSpM4ZQCRJUucMIJIkqXMGEEmS1DkDiCRJ6pwBRJIkdW5BBJAkz0hydpJrk6xLcvA01tk3yZok\ndyb5SZJXd1GrJEmavQURQIBNgR8ARwAbfDhNku2ALwJfA3YDTgI+nuTZc1eiJEnqlyy0h9ElWQf8\nQVWdPcUyHwQOrKqnjmkbBpZX1UEdlClJkmZhoZwBmak9gfPGtZ0L7DUPtUiSpBlarAFka+CGcW03\nAL+W5GHzUI8kSZqBh8x3AX2U9uuE15SSbA4cAFwF3NlRTZIkDYJNgO2Ac6vqF/3Y4GINID8DthrX\ntiVwS1XdPck6BwB/P6dVSZI02F4BnNWPDS3WAHI+cOC4tv3b9slcBXDmmWey8847z1FZC8ctt8BH\nPgL/9E/wxCfCox41+bIbbQRvfjPsumv/61i1ahUnnnhi/zesSXnMu+cx757HvFuXXnophx56KLR/\nS/thQQSQJJsCT+aByyjbJ9kN+GVV/TTJ+4HHVtXovT5OAf6kHQ3zd8B+wEuAqUbA3Amw8847s2LF\nirn4GAvG5z4HRxwBt98Op5wChx/ehIz5sHz58oE/3guNx7x7HvPuecznTd+6MCyUTqi/A1wErKHp\nw3E8MAK8p52/NfCE0YWr6irgucCzaO4fsgo4rKrGj4xZUq6/Hl784mbaYw+45BJ4wxvmL3xIkjSZ\nBXEGpKr+hSnCUFW9ZpJ1huayrsWiCk47Dd72NnjoQ+HTn4aXvhSSDa8rSdJ88H/jRe6KK+DZz4bD\nDoODD27OerzsZYYPSdLCZgBZpO69F44/Hp7yFPiP/4AvfxlOPx0233y+K1vfypUr57uEJcdj3j2P\nefc85ovfgrsV+1xJsgJYs2bNmkXfcemHP2zOeKxZA295C7z3vbDZZvNdlSRpUI2MjDA0NAQwVFUj\n/dimZ0AWkTvvhHe9C4aG4I474Hvfa4baGj4kSYvNguiEqg37znea4bT/+Z9NCDnqqKbDqSRJi5Fn\nQBa4W25p7unxjGc0NxO76CJYvdrwIUla3DwD0qHLLoM/+zO4++7pj1K55BK4+WY46aQmiCxbNrc1\nSpLUBQPINNx3XxMe1q2b/jrXXgvPf35zj45NNmnabrut+fqSl0w/SDzvec3llu22m1HJkiQtaAaQ\nce64A/7hH+Cuux5o++u/hosv7m17b34zbL/9A++33RZe+MLZ1ShJ0mJnABnnK1+BV7dPnBm9TFIF\nj3kMfP7zM9vWIx8Ju+zS3/okSRoEBpDWunXwyU/CO9/ZvP/Vr6Z+gqwkSeqdAaT16lfDmWc2r487\nDpYvn996JEkaZAaQ1nXXwd57N4+vf8pT5rsaSZIGm/cBGWObbQwfkiR1wQAC7LMPfPOb3mNDkqSu\nGECAkZEH7rchSZLmngGkte++DpmVJKkrBhBJktQ5A4gkSerckh6Gu24dfOxj6992XZIkzb0lGUC+\n+lU48US44gr48Y+bNoffSpLUnSUXQPbZB269tXn9ohfBHnvARz/qbdclSerSkgsgu+8OBx7YBI99\n9pnvaiRJWpqWXADZay94xzvmuwpJkpY2R8FIkqTOLbkAsvHG812BJElacgHk2c+e7wokSdKSCyAP\nf/h8VyBJkpZcAJEkSfPPACJJkjpnAJEkSZ0zgEiSpM4ZQCRJUucMIJIkqXMGEEmS1DkDiCRJ6pwB\nRJIkdc4AIkmSOmcAkSRJnTOASJKkzhlAJElS5wwgkiSpcwYQSZLUOQOIJEnqnAFEkiR1zgAiSZI6\nZwCRJEmdM4BIkqTOGUAkSVLnDCCSJKlzBhBJktS5BRNAkhyR5MokdyS5IMnuG1j+rUkuS3J7kquT\nnJDkYV3VK0mSercgAkiSQ4DjgdXA04CLgXOTbDHJ8i8H3t8uvxPwWuAQ4C87KViSJM3KggggwCrg\n1Ko6o6ouA94I3E4TLCayF/Cdqvp0VV1dVecBw8Ae3ZQrSZJmY94DSJKNgSHga6NtVVXAeTRBYyLf\nA4ZGL9Mk2R44CPjS3FYrSZL64SHzXQCwBbAMuGFc+w3AjhOtUFXD7eWZ7yRJu/4pVfXBOa1UkiT1\nxbyfAZlCgJpwRrIvcDTNpZqnAS8CnpfkXZ1VJ0mSerYQzoD8HLgP2Gpc+5Y8+KzIqGOAM6rqtPb9\nj5JsBpwKvHeqna1atYrly5ev17Zy5UpWrlw507olSRo4w8PDDA8Pr9e2du3avu9n3gNIVd2TZA2w\nH3A2QHtZZT/go5Os9ghg3bi2de2qafuQTOjEE09kxYoVsy9ckqQBNNE/5SMjIwwNDfV1P/MeQFon\nAKe3QeRCmlExjwA+AZDkDOCaqjq6Xf4LwKokPwC+D+xAc1bkn6YKH5IkaWFYEAGkqj7Tdio9huZS\nzA+AA6rqpnaRxwP3jlnlWJozHscCjwNuojl7Yh8QSZIWgQURQACq6mTg5EnmPXPc+9HwcWwHpUmS\npD5byKNgJEnSgDKASJKkzhlAJElS5wwgkiSpcwYQSZLUOQOIJEnqnAFEkiR1zgAiSZI6ZwCRJEmd\nM4BIkqTOGUAkSVLnDCCSJKlzBhBJktQ5A4gkSeqcAUSSJHXOACJJkjpnAJEkSZ0zgEiSpM4ZQCRJ\nUucMIJIkqXMGEEmS1DkDiCRJ6pwBRJIkdc4AIkmSOmcAkSRJnTOASJKkzhlAJElS5wwgkiSpcz0F\nkCQbJXl6klcn2axt2yLJw/tbniRJGkQPmekKSR4PfAnYCVgGfBu4FfgLIMARfaxPkiQNoF7OgJwE\nXAo8CrhjTPvngGf3oyhJkjTYZnwGBPg94Peq6o4kY9uvAB7fl6okSdJA6+UMyMaTtD+W5lKMJEnS\nlHoJIOexfj+Pajufrga+3JeqJEnSQOvlEszbgPOSjAAPA04DdgRuA/6of6VJkqRBNeMAUlX/leS3\ngFcCuwGbAZ8FTq+q/+5zfZIkaQD1Mgx3D2BNVf3tuPZlSfaoqgv7Vp0kSRpIvfQBOR/YfIL2R7Xz\nJEmSptRLAAlQE7Q/Grh9duVIkqSlYNqXYJKc1b4s4NQkd46ZvQz4beCCPtYmSZIG1EzOgGSK6U7g\nUzQdUyVJkqY07TMgVbUSIMlVwHur6ra5KkqSJA22XobhHjUXhUiSpKWjlxuRkeR5wMuAbYCHjp1X\nVb/bh7okSdIAm/EomCRvAj4N3AXsBfwYuA/YBfhuX6uTJEkDqZdhuG8B3lhVhwN3A8dW1TOAU5j8\nQXWSJEn36yWAbAt8q319J/DI9vXfAq/oR1GSJGmw9RJAbqS56RjA1cDvtK+fQI99SiRJ0tLSSwD5\nBvC89vUngZOSfAH4DPCFfhUmSZIGVy9nLN4wul5VfSTJzcDvAh8EPtbH2iRJ0oCaUQBJ8hDgrcDf\n0z73pao+AXyi34VJkqTBNaNLMFV1L/Bu5qCvR5IjklyZ5I4kFyTZfQPLL0/y10mua9e5LMlz+l2X\nJEnqv176gPwL8PR+FpHkEOB4YDXwNOBi4NwkW0yy/MbAeTQ3QnsRsCNwOHBtP+uSJElzo5czGZ8D\nPpRkZ2ANsN4zYarqKz1scxVwalWdAZDkjcBzgdcCH5pg+cOARwF7VtV9bdvVPexXkiTNg14CyN+0\nX4+eYF4By2aysfZsxhDwvvs3UlVJzqO50+pEng+cD5yc5AXATcBZwAerat1M9i9JkrrXSwB5eJ9r\n2IImtNwwrv0GmksrE9keeCZwJnAgsANwcrud9/a5PkmS1Ge9PA33rrkoZAKhOaMykY1oAsrrq6qA\ni5I8Dng7Gwggq1atYvny5eu1rVy5kpUrV86+YkmSFrnh4WGGh4fXa1u7dm3f95Pm7/f8aS/B3A68\nuKrOHtP+CWB5Vb1wgnW+CdxdVfuPaXsO8CXgYe1onfHrrADWrFmzhhUrVvT9c0iSNKhGRkYYGhoC\nGKqqkX5ss5dRMH1VVffQdGbdb7QtSdr335tkte8CTx7XtiNw/UThQ5IkLSzzHkBaJwCvT/KqJDvR\nPFn3EbQ3OEtyRpL3jVn+fwObJzkpyQ5JngscBfxVx3VLkqQeLIiHx1XVZ9p7fhwDbAX8ADigqm5q\nF3k8cO+Y5a9Jsj9wIs09Q65tX080ZFeSJC0wPQWQJNsArwKeBBxZVTcl2Q+4pqp+3Ms2q+pkmpEs\nE8175gRt36d5Bo0kSVpkZnwJJsnvApcABwAvBx7ZztoTOLZ/pUmSpEHVSx+QDwHvrapnAHePaZ/q\nxmGSJEn36yWA7AZ8eoL2G4DfmF05kiRpKeglgNwCbDlB+1OB62ZXjiRJWgp6CSD/AHwgya/T3Km0\nkgwBx9E8j0WSJGlKvQSQdwLXAD8DNgV+BFxIMxz2Pf0rTZIkDapengVzJ/DKJMcAuwKbASNV9e/9\nLk6SJA2mGQeQJENVtaaqLgcun4OaJEnSgOvlEsz3k1yW5F1Jtu97RZIkaeD1EkC2AT4OvBC4PMn5\nSY5I4hBcSZI0LTMOIFV1XVUdV1VDwG/R3IBsFXBtknP6XaAkSRo8s3oablVdBrwbeCPNaJgD+lGU\nJEkabD0HkCRDSU6gGZJ7NvCfwEv6VZgkSRpcvYyCeTfwCmB74FvAnwOfrapb+lybJEkaUDMOIMAf\nAP8HGK4qb70uSZJmrJcbka2Yi0IkSdLSMa0AkmR/4OtVdW/7elJV9ZW+VCZJkgbWdM+AfBnYGrix\nfT2ZApbNtihJkjTYphtAHl5Vd42+nqtiJEnS0jCtYbhjwgfAC5qmumvsBKxr50mSJE2pl/uADAOP\nmqD919p5kiRJU+olgISmr8d4jwG8F4gkSdqgaQ/DTXI+TfAo4Jwk94yZvQzYAfhGf8uTJEmDaCb3\nAflm+3VP4HzgtjHz7gZOAT7dn7IkSdIgm3YAqaqjAJJcBZxeVXfOVVGSJGmw9XIn1FPnohBJkrR0\nTPdOqNcBu1bVL5Jcz8SdUAGoqsf2qzhJkjSYpnsG5D3ArWNeTxpAJEmSNmRaAWTsZZeqOmXuypEk\nSUvBjO8DkmTXJDuPeX9gkk8leXeSGfcpkSRJS08vNyL7OPAUgCTbAp8DHgq8BvhA/0qTJEmDqpcA\nshNwUfv6ZcB3q+pFwKva95IkSVPqJYCMXedZwJfa1/8F/MasK5IkSQOvlwAyAhyZ5KXA7wPntO3b\nAjf2qzBJkjS4egkgq2iCxxnA8VX147b9xTS3aJckSZpSL3dCHaF58Nx47wbumaBdkiRpPT0Pm03y\nW8DONDclu7SqLulbVZIkaaDNOIAk2Rz4JPAc4A4gwMOSfBl4ZVX9sr8lSpKkQdNLH5CPAo8Fhqpq\n06p6BLA78DjgpH4WJ0mSBlMvl2AOAp5TVaP3AqGqRpK8iQdGxEiSJE2qlzMgG9NcehnvdmbRp0SS\nJC0dvQSQbwInJLn/pmNJtgSOa+dJkiRNqZczFm8GvghcneQKmlEwTwL+E3heH2uTJEkDqpf7gFyZ\nZFfguTTPhQlwCXBOVa3rc32SJGkA9dRnow0aX2gnSZKkGemlDwhJnp7ks0l+lOTf29dP73dxkiRp\nMM04gCR5HU1n02XA6TTPhNkI+EaSw/tanSRJGki9XIJ5N/COqjpxbGOSt7bz/qYfhUmSpMHVyyWY\nX2fivh9fbOdJkiRNqZcAcg4TD7d9HvDl2ZUjSZKWgl4uwawBVredTi9o2/YEngl8IMnrRxesqv8z\n+xIlSdKg6SWAvBW4E9i7nUbdBawa876AaQeQJEcAbwe2Bi4G3lxV/zqN9f4QOAv4x6p60XT3J0mS\n5k8vNyJ7TL+LSHIIcDzweuBCmiBzbpLfrKqfT7HetsCHgW/1uyZJkjR3eroPyBxYBZxaVWdU1WXA\nG2kebvfayVZIshFwJs3Imys7qVKSJPXFvAeQJBsDQ8DXRtuqqoDzgL2mWHU1cGNVnTa3FUqSpH7r\n6VbsfbYFzU3NbhjXfgOw40QrJNkbeA2w29yWJkmS5sK8nwGZQmg6sq7fmGwGfBI4vKp+1XlVkiRp\n1hbCGZCfA/cBW41r35IHnxUBeBKwLfCFJGnbNgJIcjewY1VN2idk1apVLF++fL22lStXsnLlyt6q\nlyRpgAwPDzM8PLxe29q1a/u+nzTdLWa4UrIHzYiVJwGvqKrr2uGwV1XVBVOvPeH2LgC+X1V/2r4P\ncDXw0ar68LhlHwo8edwm/hLYDHgLcHlV3TvBPlYAa9asWcOKFStmWqIkSUvWyMgIQ0NDAENVNdKP\nbc74DEiSg4FPA5+l6SS6STtrS+BQJr5L6oacAJyeZA0PDMN9BPCJdp9nANdU1dFVdTdwybiabqbp\nu3ppD/uWJEkd66UPyGrgT6rqlcA9Y9q/QzOaZcaq6jPA24BjgIuApwIHVNVN7SKPp7lBmSRJGgC9\n9AHZiTFDZse4GXh0r4VU1cnAyZPMe+YG1n1Nr/uVJEnd6+UMyI3AEydo3wtvCCZJkqahlwByGvCR\nJLvRDJPdPMmLgeOYwbNfJEnS0tXLJZj3AhsD59N0QL0AuJdmxMqJfaxNkiQNqF4eRrcO+PMkH6C5\nU+lmwL95UzBJkjRdPd+IrKpuA/oyFliSJC0tvdwH5Jyp5lfVQb2XI0mSloJezoD817j3GwO/TXN3\n0uEHLy5JkrS+XvqAvGmi9iTvo3mAnCRJ0pT6+TTc04DD+7g9SZI0oPoZQFaw/q3ZJUmSJtRLJ9Sz\nxjcBjwH2Bj7Uj6IkSdJg66UT6vh+HuuAHwAnVNXZsy9JkiQNuhkFkCTLgBOBH1fV2rkpSZIkDboZ\n9QGpqvuAbwObz005kiRpKeilE+olwBP6XYgkSVo6egkgRwLHJXlWkkcneejYqd8FSpKkwdNLJ9Rz\nx30db1mPtUiSpCWilwByYN+rkCRJS8q0A0iSdwPHVdVkZz4kSZKmZSZ9QFYDm81VIZIkaemYSQDx\nQXOSJKkvZjoKpuakCkmStKTMtBPqT5JMGUKq6tdnUY8kSVoCZhpAVgPegl2SJM3KTAPIp6rqxjmp\nRJIkLRkz6QNi/w9JktQXjoKRJEmdm/YlmKrq5bkxkiRJD2KokCRJnTOASJKkzhlAJElS5wwgkiSp\ncwYQSZLUOQOIJEnqnAFEkiR1zgAiSZI6ZwCRJEmdM4BIkqTOGUAkSVLnDCCSJKlzBhBJktQ5A4gk\nSeqcAUSSJHXOACJJkjpnAJEkSZ0zgEiSpM4ZQCRJUucMIJIkqXMGEEmS1DkDiCRJ6pwBRJIkdW7B\nBJAkRyS5MskdSS5IsvsUy74uybeS/LKdvjrV8pIkaWFZEAEkySHA8cBq4GnAxcC5SbaYZJV9gLOA\nfYE9gZ8CX0nymLmvVpIkzdaCCCDAKuDUqjqjqi4D3gjcDrx2ooWr6pVVdUpV/bCqfgK8juaz7NdZ\nxZIkqWfzHkCSbAwMAV8bbauqAs4D9prmZjYFNgZ+2fcCJUlS3817AAG2AJYBN4xrvwHYeprb+CBw\nLU1okSRJC9xD5ruAKQSoDS6UvBN4GbBPVd0951VJkqRZWwgB5OfAfcBW49q35MFnRdaT5O3AkcB+\nVfWj6exs1apVLF++fL22lStXsnLlymkXLEnSoBoeHmZ4eHi9trVr1/Z9P2m6W8yvJBcA36+qP23f\nB7ga+GhVfXiSdd4BHA3sX1X/Oo19rADWrFmzhhUrVvSveEmSBtzIyAhDQ0MAQ1U10o9tLoQzIAAn\nAKcnWQNcSDMq5hHAJwCSnAFcU1VHt++PBI4BVgJXJxk9e3JrVd3Wce2SJGmGFkQAqarPtPf8OIbm\nUswPgAOq6qZ2kccD945Z5U00o14+O25T72m3IUmSFrAFEUAAqupk4ORJ5j1z3PsndlKUJEmaEwth\nGK4kSVpiDCCSJKlzBhBJktQ5A4gkSeqcAUSSJHXOACJJkjpnAJEkSZ0zgEiSpM4ZQCRJUucMIJIk\nqXMGEEmS1DkDiCRJ6pwBRJIkdc4AIkmSOmcAkSRJnTOASJKkzhlAJElS5wwgkiSpcwYQSZLUOQOI\nJEnqnAFEkiR1zgAiSZI6ZwCRJEmdM4BIkqTOGUAkSVLnDCCSJKlzBhBJktQ5A4gkSeqcAUSSJHXO\nACJJkjpnAJEkSZ0zgEiSpM4ZQCRJUucMIJIkqXMGEEmS1DkDiCRJ6pwBRJIkdc4AIkmSOmcAkSRJ\nnTOASJKkzhlAJElS5wwgkiSpcwYQSZLUOQOIJEnqnAFEkiR1zgAiSZI6ZwCRJEmdM4BIkqTOGUAk\nSVLnDCCSJKlzBhBJktS5BRNAkhyR5MokdyS5IMnuG1j+pUkubZe/OMmBXdWq6RseHp7vEpYcj3n3\nPObd85gvfgsigCQ5BDgeWA08DbgYODfJFpMsvxdwFvA3wG8D/wj8Y5JduqlY0+Uvie55zLvnMe+e\nx3zxWxABBFgFnFpVZ1TVZcAbgduB106y/J8C/1xVJ1TVj6tqNTAC/Ek35UqSpNmY9wCSZGNgCPja\naFtVFXAesNckq+3Vzh/r3CmWlyRJC8i8BxBgC2AZcMO49huArSdZZ+sZLi9JkhaQh8x3AVMIUH1c\nfhOASy+9dDY1aYbWrl3LyMjIfJexpHjMu+cx757HvFtj/nZu0q9tLoQA8nPgPmCrce1b8uCzHKN+\nNsPlAbYDOPTQQ2deoWZlaGhovktYcjzm3fOYd89jPi+2A77Xjw3NewCpqnuSrAH2A84GSJL2/Ucn\nWe38CeY/u22fzLnAK4CrgDtnV7UkSUvKJjTh49x+bTBNf8/5leRlwOnAG4ALaUbFvATYqapuSnIG\ncE1VHd0uvxfwL8A7gS8BK9vXK6rqknn4CJIkaQbm/QwIQFV9pr3nxzE0l1Z+ABxQVTe1izweuHfM\n8ucnWQn8ZTtdDrzA8CFJ0uKwIM6ASJKkpWUhDMOVJElLjAFEkiR1bmACiA+z695MjnmS1yX5VpJf\nttNXN/Q90oPN9Od8zHp/mGRdks/NdY2DpoffLcuT/HWS69p1LkvynK7qHQQ9HPO3tsf59iRXJzkh\nycO6qnexS/KMJGcnubb9PXHwNNbZN8maJHcm+UmSV890vwMRQHyYXfdmesyBfWiO+b7AnsBPga8k\neczcVzsYejjmo+ttC3wY+NacFzlgevjdsjHNYyK2AV4E7AgcDlzbScEDoIdj/nLg/e3yO9E8Q+wQ\nmgEKmp5NaQZ/HME0bgCaZDvgizSPUNkNOAn4eJJnz2ivVbXoJ+AC4KQx7wNcAxw5yfKfAs4e13Y+\ncPJ8f5bFMs30mE+w/kbAWuDQ+f4si2Xq5Zi3x/nbwGuA04DPzffnWExTD79b3kgzKm/ZfNe+WKce\njvnHgK+OazsO+NZ8f5bFOAHrgIM3sMwHgR+OaxsGzpnJvhb9GRAfZte9Ho/5eJsCGwO/7HuBA2gW\nx3w1cGNVnTa3FQ6eHo/582n/mUnysyT/luSoJIv+d20Xejzm3wOGRi/TJNkeOIjmHlGaG3vSh7+h\nC+I+ILM01cPsdpxkHR9mNzu9HPPxPkhzWnr8D7EmNuNjnmRvmjMfu81taQOrl5/z7YFnAmcCBwI7\nACe323nv3JQ5UGZ8zKtquL088532LtrLgFOq6oNzWunSNtnf0F9L8rCqums6GxmEADKZfj/MThs2\nrWOY5J3Ay4B9quruOa9qsE14zJNsBnwSOLyqftV5VYNtqp/zjWh+Eb++/c/9oiSPA96OAWQ2Jj3m\nSfYFjqa5/HUh8GTgo0muryqPeXfSfp3239FBCCBdPcxOD+jlmAOQ5O3AkcB+VfWjuSlvIM30mD8J\n2Bb4QvtfIbSdzpPcDexYVVfOUa2Dopef8+uBu9vwMepSYOskD6mqeydZT41ejvkxwBljLjP+qA3g\np2LomyuT/Q29ZSb/VC7665JVdQ8w+jA7YL2H2U32xL7zxy7f2tDD7NTq8ZiT5B3A/6K5zf5Fc13n\nIOnhmF8K7Eozymu3djob+Hr7+qdzXPKi1+PP+Xdp/gMfa0fgesPHhvV4zB9B03FyrHXtqplgec3e\nRH9D92emf0Pnu8dtn3rtvgy4A3gVzTCsU4FfAL/Rzj8DeN+Y5fcC7gb+jOaXw1/QPCF3l/n+LItl\n6uGYH9ke4xfSJOfRadP5/iyLZZrpMZ9gfUfBzPExp3lu1VqaYYk7AM+l+W/xnfP9WRbL1MMxXw3c\nTDP0djuafyYvB86a78+yWCaaQQG70fzDsg54a/v+Ce389wOnj1l+O+BWmr58OwJ/3P5NfdZM9jsI\nl2AoH2bXuZkec+BNNKNePjtuU+9pt6EN6OGYa5Z6+N1yTZL9gRNp7l9xbfv6Q50Wvoj18HN+LM0f\nzWOBxwE30Zzte1dnRS9+vwN8g6b/RtHchwWap9S/lqbT6RNGF66qq5I8FzgBeAvNMOnDqmpGgwp8\nGJ0kSercou8DIkmSFh8DiCRJ6pwBRJIkdc4AIkmSOmcAkSRJnTOASJKkzhlAJElS5wwgkiSpcwYQ\nSZLUOQOINECSPCnJuiS7zHctvUry7SRT3ro8yWFJbuyqJkn9ZwCRFpAkp7UB4r726+jr7WewmcX+\nfIXn0zwjCIAkP03yx+OWORNYkCErybL2+3bQfNciLWQD8TA6acD8M/BHwNhHid808aITWtSPIK+q\nm6exzF3AXR2Uc78kGzW73uADtBb18Ze64hkQaeG5q6puqqobx0wFkOSgJN9J8qskP09ydpInTrah\nJI9OclaSG5PcnuSyJIeOmb9Nkn8Ys73PJ3nCFNvbr/3v/jlJfpjkjiTfTbLzuOVemuRHSe5KcmWS\nt46b/+Yklye5M8nPkgyPmXf/JZgk36Z5wunH2v3e3ba/LslN7etd2nlPGrePI5NcOub9rkm+nOTW\nJNcn+UQPZyPSAAAFS0lEQVSSX5/isx6W5KYkL0hyCXAn8JgkeyT5anu8bk7y9SS7jVn1SpqzUF9s\n6/rJmG2+KMlIe9wuT/KuNthIS44/+NLi8nDgw8AKYD+a/7b/7xTLvx94MnAAsBPwx8AvAJJsDHwF\n+DmwN/B04A7gn6fxR/FDNI/h3h24GTh7dJ0kewDDwCeB36K5nPK+JC9v5+9J87jvo4Ad2tq+M8l+\nDgaub5fdmiaMwAOPDaeqLqF5ZPvLx627kuZSDUkeDXwduAD4beDAdltnbeBzPhJ4G80ZqafQHLtH\nAn8H7NlOVwLnJHl4u87uNN+XV7Q179nWsC/w8faz7wS8CTgM+J8bqEEaTFXl5OS0QCbgNOAe4L/H\nTJ+eYvmtgXXAb7bvn9S+36V9/yXg1EnWfTXww3FtD6MJIftOss5+7fb/YEzb5sDto23Ap4Avjlvv\neOCi9vVLaULPIybZx7eBD415/1Pgj8ctcxhw45j3bwcuHfN+F+A+4Int+9XAF8ZtY7v2s2w3SR2H\ntdvYaQPfs2XArcD+Y96vAw4at9w3gLdN8D34r/n+uXNymo/JMyDSwvN14KnAbu30ltEZSXZI8qkk\nVyS5Bbic5kzANpNs62TglUnWJPlAkv8xZt5uwM5J/nt0ogkGG9MEmckUzZmE5k3VL4D/AEYvw+wM\nfHfcOt8Fdmxffxn4GXBlktOTrEyyyRT7m45hYIckK9r3rwC+X1VXtu93A/Yf91n/rf0sU33WO6rq\nsrENSbZO8vEkP0lyM80ZoE2Y/Hsw6qnAMeNq+N/AY9uzUdKSYidUaeG5bcwfzvG+BPwEeC3NpYmH\nAhe3Xx+kqr6UZBvgucCzgG8k+UhVHQ1sRhMkXsWDO07OpNPr/btrv4YHj8S5f/tV9d9tn4l9gf2B\nY4HVSX6nqm7tYb9U1bVJvkVzGWYE+EOasy6jNgM+T3MpZ/xnvW6KTd8+QduZwKbAm4GraTrD/j8m\n+R6Mq+F/AmdPUP89G1hXGjgGEGmRSLIlTX+OV1bV99u2fXnwH/v13lfVz4HTgdOTnA8cAxxN84f6\nBTSXMm6bSSk0/Rr+sa1h87au0Q6fl9D0Jxlrb+D+MwlVdR/wNeBrSY6lOYuwL/DFCfZ3N81ljQ35\ne+A9ST4PPAH4zJh5IzQh7Kqqmu0w5d8FXlNV5wK0nYAfNTqzqu5Lct8ENV8E7FhVV8xy/9JA8BKM\ntHj8AvgV8IYk2yfZj6ZD6nj3/4ef5Ngkz09zg7KnAAfRBARoOomuBT6fZO8k2yX5/SQfS7LVBmr5\niyT7JtmVJtxcxwPh4XjggCRHtZeMXgO8YbTWJAcn+ZMkT23PzvwRTZ+JH0+yr6uAfZI8dqpRK8Bn\nafqj/BXw1TZ4jfoYsBVwVpKh9vg9J8lpG/icE7kceFWSHZPsRfP57xi3zNXAs5JslWQ0nLwHeG07\n8mXndvrDJO9BWoIMINIi0Z41OAT4H8C/0/xBf/tEi455fQ/wAZrLNN+gGUp6aLu924DfowkPn6MJ\nJqfyQKfKSUuhuZTxV8CFwKOBg9v6qKp/pbkE8gqafhZ/DhxVVaNDbX8FvISmr8slNJeTDqmqyyeo\nn3b9HYAraPqOTFxU1VrgHJq+Fn8/bt61NGdhHgp8FfghTVD6xRSfczJ/BPwGzRmNvwNOmGA7q4Dn\n0ASRC9sa/plmVM+BNJdsvgf8Kc0oGmnJyezPRkpaKtqzLl8BHllVE/WPkKRp8QyIJEnqnAFEkiR1\nzkswkiSpc54BkSRJnTOASJKkzhlAJElS5wwgkiSpcwYQSZLUOQOIJEnqnAFEkiR1zgAiSZI69/8B\nueo13yoGklwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114e9aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve score = 0.9931149252757294\n",
      "Accuracy = 0.9616858237547893\n"
     ]
    }
   ],
   "source": [
    "pred = best_estimator_tfidf.predict_proba(test_tfidf.toarray())[:,1]\n",
    "print(classification_report(test_target, best_estimator_tfidf.predict(test_tfidf.toarray())))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_target, pred)\n",
    "acc = metrics.accuracy_score(y_pred=best_estimator_tfidf.predict(test_tfidf.toarray()), y_true=test_target)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n",
    "print('Area under ROC curve score = {}'.format(roc_auc_score(test_target, pred)))\n",
    "print('Accuracy = {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Теперь проверим написанные вручную алгоритмы: трехслойный перцептрон и логистическую регрессию ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Класс, реализующий логистическую регрессию с L2 регуляризацией\n",
    "\n",
    "class LogisticRegression_m(object):\n",
    "\n",
    "    def __init__(self, eta=0.1, C=0, n_iter=100, method='batch', verbose=False):\n",
    "        \"\"\" Конструктор. Параметры:\n",
    "            eta - learning rate, определяет величину шага в сторону антиградиента, вещественное число\n",
    "            C - параметр L2 регуляризации, вещественное число\n",
    "            n_iter - число итераций по данным, целое число\n",
    "            method - возможные значения: batch, mini-batch, stoch. Тип градиентного спуска.\n",
    "            verbose - использовать для отладки и мониторинга сходимости \"\"\"\n",
    "        self.eta_ = eta\n",
    "        self.n_iter_ = n_iter\n",
    "        self.C_ = C\n",
    "        self.method_ = method\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Функция обучения регрессии. Параметры:\n",
    "            X - numpy array-like массив. В строках наблюдения, в столбцах пременные\n",
    "            y - вектор ответов \"\"\"\n",
    "        self.all_w_ = np.zeros((np.unique(y).size, X.shape[1] + 1))\n",
    "        self.num_labels = np.unique(y).size\n",
    "\n",
    "        if self.method_ == 'batch':\n",
    "            self._batch_grad(X, y)\n",
    "        if self.method_ == 'stoch':\n",
    "            self._stoch_grad(X, y)\n",
    "        if self.method_ == 'mini-batch':\n",
    "            self._minibatch_grad(X, y)\n",
    "        return self\n",
    "\n",
    "    def _batch_grad(self, X, y):\n",
    "        \"\"\" Реализация т.н. batch градиентного спуска. Функция n_iter раз проходит по всему датасету,\n",
    "            каждый раз вызывая один шаг спуска \"\"\"\n",
    "        for i in range(self.n_iter_):\n",
    "            self._batch_step(X, y)\n",
    "\n",
    "    def _batch_step(self, X, y):\n",
    "        \"\"\" Шаг batch градиентного спуска \"\"\"\n",
    "        self._one_v_rest(X, y)\n",
    "\n",
    "    def _one_v_rest(self, X, y):\n",
    "        \"\"\" Реализация поддержки многоклассовой задачи методом one vs rest \"\"\"\n",
    "        for c in np.unique(y):\n",
    "            y_ovr = np.where(y == c, 1, 0)\n",
    "            error = y_ovr - self.sigmoid(X, c)\n",
    "            self.all_w_[c, 0] += self.eta_ * error.sum() - self.eta_ * \\\n",
    "                self.C_ * self.all_w_[c, 0]\n",
    "            self.all_w_[c, 1:] += self.eta_ * X.T @ error - \\\n",
    "                self.eta_ * self.C_ * self.all_w_[c, 1:]\n",
    "\n",
    "    def _stoch_grad(self, X, y):\n",
    "        \"\"\" Реализация стохастического градиентного спуска. Рекомендуется при большом количестве данных. \"\"\"\n",
    "        for i in range(self.n_iter_):\n",
    "            self._stoch_step(X, y)\n",
    "\n",
    "    def _stoch_step(self, X, y):\n",
    "        \"\"\" Реализация шага стохастического градиентного спуска \"\"\"\n",
    "        rand_indices = np.random.permutation(y.size)\n",
    "        rand_choice = np.random.randint(0, y.size)\n",
    "        sample = X[rand_indices, :][rand_choice, :]\n",
    "\n",
    "        error = y[rand_indices][rand_choice] - self.sigmoid(sample)\n",
    "        self.w_[0] += self.eta_ * error - self.eta_ * self.C_ * self.w_[0]\n",
    "        self.w_[1:] += self.eta_ * sample * \\\n",
    "            error - self.eta_ * self.C_ * self.w_[1:]\n",
    "        self.errors_.append(self.logit_loss(\n",
    "            sample, y[rand_indices][rand_choice]))\n",
    "\n",
    "    def sigmoid(self, X, c):\n",
    "        \"\"\" Функция связи логистической регрессии \"\"\"\n",
    "        z = self.net_input(X, c)\n",
    "        return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "    def net_input(self, X, c):\n",
    "        \"\"\" Скалярное произведение полученных после обучения весов и переменных наблюдения \"\"\"\n",
    "        return (X @ self.all_w_[c, 1:] + self.all_w_[c, 0])\n",
    "\n",
    "    def logit_loss(self, X, y):\n",
    "        \"\"\" Кросс-энтропия, целевая функция \"\"\"\n",
    "        return -(y * np.log(self.sigmoid(X)) + (1 - y) *\n",
    "                 np.log(1 - self.sigmoid(X))).sum()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Возвращает ответы \"\"\"\n",
    "        probas = self._predict_one_v_rest(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Возвращает вероятности ответов \"\"\"\n",
    "        return self._predict_one_v_rest(X)\n",
    "\n",
    "    def _predict_one_v_rest(self, X):\n",
    "        \"\"\" Реализация для поддержки многоклассовой задачи методом one vs rest \"\"\"\n",
    "        probas = np.zeros((X.shape[0], self.num_labels))\n",
    "        for c in range(self.num_labels):\n",
    "            probas[:, c] = self.sigmoid(X, c)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAF5CAYAAACm4JG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f3f9dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve score = 0.9914311818834431\n",
      "Accuracy = 0.9501915708812261\n"
     ]
    }
   ],
   "source": [
    "lrm = LogisticRegression_m(C=0.1, n_iter=100)\n",
    "lrm.fit(train_tfidf, train_target)\n",
    "predi = lrm.predict_proba(test_tfidf)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_target, predi[:, 1])\n",
    "acc = metrics.accuracy_score(y_pred=lrm.predict(test_tfidf.toarray()), y_true=test_target)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()\n",
    "print('Area under ROC curve score = {}'.format(roc_auc_score(test_target, predi[:,1])))\n",
    "print('Accuracy = {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class BagOfWordsVectorizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dictionary = OrderedDict()\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, X):\n",
    "        X_in = np.array(X)\n",
    "        X_in = self._make_dictionary(X_in)\n",
    "        self._vectorize(X_in)\n",
    "        return self\n",
    "\n",
    "    def _make_dictionary(self, X):\n",
    "        uniques = np.unique(X)\n",
    "        self.dictionary.update(zip(uniques, np.zeros((1, uniques.size))))\n",
    "        return X\n",
    "\n",
    "    def _vectorize(self, X):\n",
    "        X_vectorized = np.zeros((X.shape[0], X.shape[1]))\n",
    "        for num, row in enumerate(X):\n",
    "            row_dict = self.dictionary\n",
    "            for val in row:\n",
    "                if row_dict.get(val) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    row_dict[val] += 1\n",
    "\n",
    "            X_vectorized[num, :] = np.array(list(row_dict.values()))\n",
    "\n",
    "        return X_vectorized\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._vectorize(X)\n",
    "\n",
    "    def get_words(self):\n",
    "        return list(self.dictionary.keys())\n",
    "\n",
    "\n",
    "class FinalHWData(object):\n",
    "\n",
    "    def __init__(self, categories, remove):\n",
    "        self.categories = categories\n",
    "        self.remove = remove\n",
    "        self._init_data()\n",
    "\n",
    "    def _init_data(self):\n",
    "        self.train = fetch_20newsgroups(subset='train', categories=cats,\n",
    "                                        remove=('headers', 'footers', 'quotes'))\n",
    "        self.test = fetch_20newsgroups(subset='test', categories=cats,\n",
    "                                       remove=('headers', 'footers', 'quotes'))\n",
    "        self.train_target = self.train.target\n",
    "        self.test_target = self.test.target\n",
    "\n",
    "    def get_data(self, kind):\n",
    "        if kind.lower() == 'test':\n",
    "            return self.test.data\n",
    "        elif kind.lower() == 'train':\n",
    "            return self.train.data\n",
    "    \n",
    "    def get_target(self, kind):\n",
    "        if kind.lower() == 'test':\n",
    "            return self.test.target\n",
    "        elif kind.lower() == 'train':\n",
    "            return self.train.target\n",
    "\n",
    "\n",
    "class DataPreparator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_normal = []\n",
    "        self.test_normal = []\n",
    "\n",
    "    def normalize(self, train, test, stop_words):\n",
    "        for text in train:\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            tokens = list(filter(lambda x: x not in stop_words, tokens))\n",
    "            wnl = WordNetLemmatizer()\n",
    "            normal_form_list = [wnl.lemmatize(i, j[0].lower()) if j[0].lower() in ['a', 'n', 'v']\n",
    "                                else wnl.lemmatize(i) for i, j in pos_tag(tokens)]\n",
    "            normal_form = ' '.join(normal_form_list)\n",
    "            normal_form = re.sub(r'\\d+', '', normal_form.replace('*', ''))\n",
    "            self.train_normal.append(normal_form)\n",
    "\n",
    "        for text in test:\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            tokens = list(filter(lambda x: x not in stop_words, tokens))\n",
    "            wnl = WordNetLemmatizer()\n",
    "            normal_form_list = [wnl.lemmatize(i, j[0].lower()) if j[0].lower() in ['a', 'n', 'v']\n",
    "                                else wnl.lemmatize(i) for i, j in pos_tag(tokens)]\n",
    "            normal_form = ' '.join(normal_form_list)\n",
    "            normal_form = re.sub(r'\\d+', '', normal_form.replace('*', ''))\n",
    "            self.test_normal.append(normal_form)\n",
    "\n",
    "    def get_data(self, kind):\n",
    "        if kind.lower() == 'train':\n",
    "            return self.train_normal\n",
    "        elif kind.lower() == 'test':\n",
    "            return self.test_normal\n",
    "\n",
    "\n",
    "class ModelBuilder(object):\n",
    "\n",
    "    def __init__(self, cv_folds, models, models_names, param_grids):\n",
    "        self.cv_folds = cv_folds\n",
    "        self.models = models\n",
    "        self.models_names = models_names\n",
    "        self.param_grids = param_grids\n",
    "\n",
    "    def fit(self, train, target):\n",
    "        cross_validator = StratifiedKFold(\n",
    "            y=target, n_folds=self.cv_folds, shuffle=True, random_state=0)\n",
    "        best_score = 0\n",
    "        for clf, params, name in zip(self.models, self.param_grids, self.models_names):\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=params,\n",
    "                              scoring='accuracy', cv=cross_validator)\n",
    "            gs.fit(train.toarray(), target)\n",
    "            print('For {} the score is {} with parameters {}'.format(\n",
    "                name, gs.best_score_, gs.best_params_))\n",
    "            if gs.best_score_ > best_score:\n",
    "                best_score = gs.best_score_\n",
    "                best_estimator = gs.best_estimator_\n",
    "        self.estimator = best_estimator\n",
    "        print('The best estimator is {}\\nwith accuracy = {}'.format(\n",
    "            best_estimator, best_score))\n",
    "\n",
    "    def test_and_report(self, roc_curve, report, test, target):\n",
    "        pred = self.estimator.predict_proba(test.toarray())[:, 1]\n",
    "        print(classification_report(target, self.estimator.predict(test.toarray())))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(target, pred)\n",
    "        acc = metrics.accuracy(y_pred=self.estimator.predict(\n",
    "            test.toarray()), y_true=target)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.show()\n",
    "        print('Area under ROC curve score = {}'.format(\n",
    "            roc_auc_score(target, pred)))\n",
    "        print('Accuracy = {}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic Regression the score is 0.9507221750212405 with parameters {'random_state': 1, 'C': 10, 'class_weight': None}\n",
      "For Random Forest the score is 0.9252336448598131 with parameters {'n_estimators': 300, 'random_state': 0, 'max_depth': None, 'class_weight': 'balanced'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-08e0dc92b3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtr_vec\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreparator_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mte_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreparator_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_and_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mte_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-ca4f46ac7901>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train, target)\u001b[0m\n\u001b[1;32m    118\u001b[0m             gs = GridSearchCV(estimator=clf, param_grid=params,\n\u001b[1;32m    119\u001b[0m                               scoring='accuracy', cv=cross_validator)\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             print('For {} the score is {} with parameters {}'.format(\n\u001b[1;32m    122\u001b[0m                 name, gs.best_score_, gs.best_params_))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \"\"\"\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    560\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 562\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m           for train, test in cv.split(X, y, groups))\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    375\u001b[0m                                            max_leaf_nodes, self.min_impurity_split)\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_handle = FinalHWData(categories=cats, remove=('headers', 'footers', 'quotes'))\n",
    "preparator_handle = DataPreparator()\n",
    "preparator_handle.normalize(train=data_handle.get_data(kind='train'),\n",
    "                            test=data_handle.get_data(kind='test'),\n",
    "                            stop_words=ignore_symbs)\n",
    "builder = ModelBuilder(cv_folds=10, models=models[:3], models_names=models_names[:3], param_grids=param_grids[:3])\n",
    "vec = CountVectorizer(analyzer='word')\n",
    "tr_vec= vec.fit_transform(preparator_handle.get_data(kind='train'))\n",
    "te_vec = vec.transform(preparator_handle.get_data(kind='test'))\n",
    "builder.fit(train=tr_vec, target=data_handle.get_target(kind='train'))\n",
    "builder.test_and_report(test=te_vec, target=data_handle.get_target(kind='test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
